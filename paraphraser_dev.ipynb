{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6a59f-8b40-4867-9bef-1becf09727ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692b7a5-05f8-4639-be0f-fe504d8616c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "informal_to_formal_pipeline = pipeline(\"text2text-generation\", \n",
    "                                       model=AutoModelForSeq2SeqLM.from_pretrained(\"informal_to_formal_styletransfer\"), \n",
    "                                       tokenizer=AutoTokenizer.from_pretrained(\"informal_to_formal_styletransfer\"))\n",
    "\n",
    "formal_to_informal_pipeline = pipeline(\"text2text-generation\", \n",
    "                                       model=AutoModelForSeq2SeqLM.from_pretrained(\"formal_to_informal_styletransfer\"), \n",
    "                                       tokenizer=AutoTokenizer.from_pretrained(\"formal_to_informal_styletransfer\"))\n",
    "\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5_paraphraser')\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5_paraphraser')\n",
    "def t5_pipeline(t5_model, t5_tokenizer, sentence): \n",
    "    torch.manual_seed(42)\n",
    "    encoding = tokenizer.encode_plus(\"paraphrase: \" + sentence + \" </s>\",  pad_to_max_length=True, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "    beam_outputs = model.generate(input_ids=input_ids, attention_mask=attention_masks, do_sample=True, max_length=256, top_k=120,\n",
    "                                  top_p=0.98, early_stopping=True, num_return_sequences=10)\n",
    "    final_outputs =[]\n",
    "    for beam_output in beam_outputs:\n",
    "        sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "            final_outputs.append(sent)\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad7148-6442-4f6e-99cb-c5b226d06437",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The best cloud on the market is Microsoft Azure.\"\n",
    "\n",
    "print(f\"Original Sentence: {sentence}\\n\")\n",
    "print(f\"Informal to Formal:\\n\\t{informal_to_formal_pipeline(sentence)[0]['generated_text']}\")\n",
    "print(f\"Formal to Informal:\\n\\t{formal_to_informal_pipeline(sentence)[0]['generated_text']}\")\n",
    "print(\"T5 Options:\")\n",
    "for idx, sent in enumerate(t5_pipeline(t5_model, t5_tokenizer, sentence)): \n",
    "    print(f\"{idx:5d}\\t{sent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded275d-cbab-4dc1-aa1a-bf1de278b753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "style-transfer",
   "language": "python",
   "name": "style-transfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
